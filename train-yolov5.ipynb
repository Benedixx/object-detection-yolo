{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7491276,"sourceType":"datasetVersion","datasetId":4361609}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-27T09:59:56.937088Z","iopub.execute_input":"2024-01-27T09:59:56.937660Z","iopub.status.idle":"2024-01-27T10:00:00.010560Z","shell.execute_reply.started":"2024-01-27T09:59:56.937578Z","shell.execute_reply":"2024-01-27T10:00:00.009142Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 16383, done.\u001b[K\nremote: Counting objects: 100% (277/277), done.\u001b[K\nremote: Compressing objects: 100% (207/207), done.\u001b[K\nremote: Total 16383 (delta 138), reused 151 (delta 70), pack-reused 16106\u001b[K\nReceiving objects: 100% (16383/16383), 15.14 MiB | 18.50 MiB/s, done.\nResolving deltas: 100% (11171/11171), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.chdir('yolov5')","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:00:00.013499Z","iopub.execute_input":"2024-01-27T10:00:00.013940Z","iopub.status.idle":"2024-01-27T10:00:00.021260Z","shell.execute_reply.started":"2024-01-27T10:00:00.013902Z","shell.execute_reply":"2024-01-27T10:00:00.020071Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:00:00.022933Z","iopub.execute_input":"2024-01-27T10:00:00.023582Z","iopub.status.idle":"2024-01-27T10:00:00.040241Z","shell.execute_reply.started":"2024-01-27T10:00:00.023547Z","shell.execute_reply":"2024-01-27T10:00:00.039286Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/yolov5'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:00:00.041677Z","iopub.execute_input":"2024-01-27T10:00:00.042221Z","iopub.status.idle":"2024-01-27T10:00:16.665333Z","shell.execute_reply.started":"2024-01-27T10:00:00.042187Z","shell.execute_reply":"2024-01-27T10:00:16.664234Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gitpython>=3.1.30 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.1.32)\nRequirement already satisfied: matplotlib>=3.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.7.4)\nRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.24.3)\nRequirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.9.0.80)\nCollecting Pillow>=10.0.1 (from -r requirements.txt (line 9))\n  Obtaining dependency information for Pillow>=10.0.1 from https://files.pythonhosted.org/packages/cb/c3/98faa3e92cf866b9446c4842f1fe847e672b2f54e000cb984157b8095797/pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (5.9.3)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.11.4)\nCollecting thop>=0.1.1 (from -r requirements.txt (line 14))\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.0.0)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.15.1)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (4.66.1)\nCollecting ultralytics>=8.0.232 (from -r requirements.txt (line 18))\n  Obtaining dependency information for ultralytics>=8.0.232 from https://files.pythonhosted.org/packages/14/db/f1ec308131cf4bf2f5f3a43a679dbef06e67e45525492be551b21e9e19d7/ultralytics-8.1.6-py3-none-any.whl.metadata\n  Downloading ultralytics-8.1.6-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (2.0.3)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.12.2)\nRequirement already satisfied: setuptools>=65.5.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 42)) (68.1.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.11.17)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics>=8.0.232->-r requirements.txt (line 18)) (9.0.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\nDownloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics-8.1.6-py3-none-any.whl (705 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m705.0/705.0 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: Pillow, thop, ultralytics\n  Attempting uninstall: Pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Pillow-10.2.0 thop-0.1.1.post2209072238 ultralytics-8.1.6\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install shapely=2.0.1 & numpy=1.16.0","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:00:16.669558Z","iopub.execute_input":"2024-01-27T10:00:16.669868Z","iopub.status.idle":"2024-01-27T10:00:17.597575Z","shell.execute_reply.started":"2024-01-27T10:00:16.669841Z","shell.execute_reply":"2024-01-27T10:00:17.596490Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_key = user_secrets.get_secret(\"secret key\")","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:06:56.127580Z","iopub.execute_input":"2024-01-27T10:06:56.127998Z","iopub.status.idle":"2024-01-27T10:06:56.392826Z","shell.execute_reply.started":"2024-01-27T10:06:56.127963Z","shell.execute_reply":"2024-01-27T10:06:56.391940Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=secret_key)\nproject = rf.workspace(\"kmutt-2nwsx\").project(\"rock-paper-scissor-pezaz\")\ndataset = project.version(4).download(\"yolov5\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:23:21.235562Z","iopub.execute_input":"2024-01-27T10:23:21.235994Z","iopub.status.idle":"2024-01-27T10:23:38.737123Z","shell.execute_reply.started":"2024-01-27T10:23:21.235960Z","shell.execute_reply":"2024-01-27T10:23:38.736113Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Requirement already satisfied: roboflow in /opt/conda/lib/python3.10/site-packages (1.1.17)\nRequirement already satisfied: certifi==2023.7.22 in /opt/conda/lib/python3.10/site-packages (from roboflow) (2023.7.22)\nRequirement already satisfied: chardet==4.0.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.0.0)\nRequirement already satisfied: cycler==0.10.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.0)\nRequirement already satisfied: idna==2.10 in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.10)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.4)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.24.3)\nRequirement already satisfied: opencv-python-headless==4.8.0.74 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.8.0.74)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (10.2.0)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.8.2)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\nRequirement already satisfied: supervision in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.18.0)\nRequirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.15)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.1)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.1)\nRequirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\nRequirement already satisfied: python-magic in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.4.27)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.1.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.42.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.2.0)\nRequirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from supervision->roboflow) (0.7.1)\nRequirement already satisfied: scipy<2.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from supervision->roboflow) (1.11.4)\nloading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in Rock-Paper-Scissor-4 to yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113656/113656 [00:02<00:00, 42245.49it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to Rock-Paper-Scissor-4 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1384/1384 [00:00<00:00, 4190.55it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!python train.py --img 512 --batch 16 --epochs 20 --data /kaggle/working/yolov5/Rock-Paper-Scissor-4/data.yaml --weights yolov5s.pt","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:28:20.996008Z","iopub.execute_input":"2024-01-27T10:28:20.996819Z","iopub.status.idle":"2024-01-27T10:42:43.291957Z","shell.execute_reply.started":"2024-01-27T10:28:20.996780Z","shell.execute_reply":"2024-01-27T10:42:43.290761Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/kaggle/working/yolov5/Rock-Paper-Scissor-4/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=16, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\nOverriding model.yaml nc=80 with nc=3\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\nModel summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n\nTransferred 343/349 items from yolov5s.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov5/Rock-Paper-Scissor-4/train/labels.cache..\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/yolov5/Rock-Paper-Scissor-4/train/images/1665130666126_jpg.rf.d36c00e31f1fef60161fd95ac88fd723.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2439]\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/working/yolov5/Rock-Paper-Scissor-4/train/images/1665130666209_jpg.rf.41e2de12bb9c93ff308e0b61ed1c2569.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048]\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov5/Rock-Paper-Scissor-4/valid/labels.cache... \u001b[0m\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.77 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\nPlotting labels to runs/train/exp5/labels.jpg... \n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nImage sizes 512 train, 512 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/train/exp5\u001b[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       0/19      3.02G     0.0966    0.03869    0.04044         26        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107     0.0875     0.0963     0.0659      0.014\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/19      3.02G    0.07021    0.04166     0.0358         24        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.177      0.371      0.135     0.0489\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/19      3.02G    0.06276    0.03563    0.03209         21        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.184      0.393      0.177     0.0519\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/19      3.02G    0.05812    0.03503    0.02802         21        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.207      0.372      0.237     0.0587\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/19      3.02G    0.05232     0.0337    0.02439         30        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.504       0.51      0.512      0.221\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/19      3.02G     0.0498     0.0322    0.02201         37        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.608      0.589      0.614      0.185\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/19      3.02G    0.04681    0.03215    0.02016         36        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.615      0.627      0.605      0.192\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/19      3.02G    0.04284    0.03031    0.01838         26        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.617      0.755      0.717      0.299\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/19      3.02G    0.04231    0.02892    0.01683         22        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.869      0.627      0.718      0.298\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/19      3.02G     0.0416    0.02916    0.01586         19        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107       0.88      0.674      0.806       0.34\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/19      3.02G    0.03983    0.02877    0.01427         31        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.869      0.669      0.761      0.332\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/19      3.02G    0.03856    0.02859    0.01371         34        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.833      0.725      0.776      0.301\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/19      3.02G    0.03747    0.02844    0.01334         26        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.826      0.697       0.78      0.312\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/19      3.02G    0.03671     0.0271    0.01205         30        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.841      0.718      0.791      0.299\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/19      3.02G     0.0349    0.02648     0.0114         28        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.825      0.634       0.73      0.308\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/19      3.02G    0.03446    0.02679     0.0109         27        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.974      0.641      0.768      0.379\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/19      3.02G    0.03405    0.02636    0.01068         21        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.903      0.624      0.761      0.367\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/19      3.02G    0.03374    0.02555   0.009793         18        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.839      0.671      0.721      0.304\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/19      3.02G    0.03204    0.02615   0.008762         33        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.806      0.637      0.712      0.279\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/19      3.02G    0.03171    0.02502    0.00874         26        512: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.831      0.677      0.743      0.317\n\n20 epochs completed in 0.220 hours.\nOptimizer stripped from runs/train/exp5/weights/last.pt, 14.4MB\nOptimizer stripped from runs/train/exp5/weights/best.pt, 14.4MB\n\nValidating runs/train/exp5/weights/best.pt...\nFusing layers... \nModel summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all         53        107      0.974      0.641      0.769       0.38\n                 Paper         53         45      0.993      0.711      0.801      0.354\n                  Rock         53         35      0.958      0.655      0.781      0.466\n               Scissor         53         27       0.97      0.556      0.725      0.319\nResults saved to \u001b[1mruns/train/exp5\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!python benchmarks.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best.pt --img 512","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:42:55.966366Z","iopub.execute_input":"2024-01-27T10:42:55.966800Z","iopub.status.idle":"2024-01-27T10:47:26.096284Z","shell.execute_reply.started":"2024-01-27T10:42:55.966764Z","shell.execute_reply":"2024-01-27T10:47:26.095121Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mbenchmarks: \u001b[0mweights=/kaggle/working/yolov5/runs/train/exp5/weights/best.pt, imgsz=512, batch_size=1, data=/kaggle/working/yolov5/data/coco128.yaml, device=, half=False, test=False, pt_only=False, hard_fail=False\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nFusing layers... \nModel summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n\nDataset not found âš ï¸, missing paths ['/kaggle/working/datasets/coco128/images/train2017']\nDownloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.66M/6.66M [00:00<00:00, 120MB/s]\nDataset download success âœ… (1.0s), saved to \u001b[1m/kaggle/working/datasets\u001b[0m\nWARNING âš ï¸ Benchmark failure for PyTorch: /kaggle/working/yolov5/runs/train/exp5/weights/best.pt (3 classes) trained on different --data than what you passed (80 classes). Pass correct combination of --weights and --data that are trained together.\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nFusing layers... \nModel summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /kaggle/working/yolov5/runs/train/exp5/weights/best.pt with output shape (1, 16128, 8) (13.7 MB)\n\n\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.0...\n\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 1.4s, saved as /kaggle/working/yolov5/runs/train/exp5/weights/best.torchscript (27.2 MB)\n\nExport complete (1.7s)\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/train/exp5/weights\u001b[0m\nDetect:          python detect.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best.torchscript \nValidate:        python val.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best.torchscript \nPyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/kaggle/working/yolov5/runs/train/exp5/weights/best.torchscript')  \nVisualize:       https://netron.app\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nLoading /kaggle/working/yolov5/runs/train/exp5/weights/best.torchscript for TorchScript inference...\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco128/labels/train2017... 126 images, 2\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/coco128/labels/train2017.cache\n                 Class     Images  Instances          P          R      mAP50   \n                   all        128        929   0.000589    0.00089   0.000205   7.56e-05\nSpeed: 0.2ms pre-process, 4.8ms inference, 1.9ms NMS per image at shape (1, 3, 512, 512)\nResults saved to \u001b[1mruns/val/exp2\u001b[0m\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nFusing layers... \nModel summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /kaggle/working/yolov5/runs/train/exp5/weights/best.pt with output shape (1, 16128, 8) (13.7 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0...\n================ Diagnostic Run torch.onnx.export version 2.0.0 ================\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as /kaggle/working/yolov5/runs/train/exp5/weights/best.onnx (27.1 MB)\n\nExport complete (1.2s)\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/train/exp5/weights\u001b[0m\nDetect:          python detect.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best.onnx \nValidate:        python val.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best.onnx \nPyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/kaggle/working/yolov5/runs/train/exp5/weights/best.onnx')  \nVisualize:       https://netron.app\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nLoading /kaggle/working/yolov5/runs/train/exp5/weights/best.onnx for ONNX Runtime inference...\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime-gpu'] not found, attempting AutoUpdate...\nCollecting onnxruntime-gpu\n  Obtaining dependency information for onnxruntime-gpu from https://files.pythonhosted.org/packages/ac/c2/7f5cb0f36f7385e041453472404870db1be8ba66dcc70854d5103eef9ff0/onnxruntime_gpu-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading onnxruntime_gpu-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nCollecting coloredlogs (from onnxruntime-gpu)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (23.5.26)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.24.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.12)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime-gpu) (3.0.9)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\nDownloading onnxruntime_gpu-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m157.1/157.1 MB\u001b[0m \u001b[31m202.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.16.3\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 16.7s, installed 1 package: ['onnxruntime-gpu']\n\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\nForcing --batch-size 1 square inference (1,3,512,512) for non-PyTorch models\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco128/labels/train2017.cache... 126 ima\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all        128        929   0.000589    0.00089   0.000205   7.56e-05\nSpeed: 0.2ms pre-process, 8.1ms inference, 1.2ms NMS per image at shape (1, 3, 512, 512)\nResults saved to \u001b[1mruns/val/exp3\u001b[0m\nWARNING âš ï¸ Benchmark failure for OpenVINO: inference not supported on GPU\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nFusing layers... \nModel summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /kaggle/working/yolov5/runs/train/exp5/weights/best.pt with output shape (1, 16128, 8) (13.7 MB)\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['nvidia-tensorrt'] not found, attempting AutoUpdate...\nLooking in indexes: https://pypi.ngc.nvidia.com\nCollecting nvidia-tensorrt\n  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-tensorrt/nvidia_tensorrt-8.4.3.1-cp310-none-linux_x86_64.whl (340.9 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m340.9/340.9 MB\u001b[0m \u001b[31m210.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11 (from nvidia-tensorrt)\n  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cuda-runtime-cu11/nvidia-cuda-runtime-cu11-2022.4.25.tar.gz (16 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting nvidia-cudnn-cu11 (from nvidia-tensorrt)\n  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cudnn-cu11/nvidia-cudnn-cu11-2022.5.19.tar.gz (16 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting nvidia-cublas-cu11 (from nvidia-tensorrt)\n  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cublas-cu11/nvidia-cublas-cu11-2022.4.8.tar.gz (16 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting nvidia-cublas-cu117 (from nvidia-cublas-cu11->nvidia-tensorrt)\n  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cublas-cu117/nvidia_cublas_cu117-11.10.1.25-py3-none-manylinux1_x86_64.whl (333.1 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m333.1/333.1 MB\u001b[0m \u001b[31m232.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu117 (from nvidia-cuda-runtime-cu11->nvidia-tensorrt)\n  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cuda-runtime-cu117/nvidia_cuda_runtime_cu117-11.7.60-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m255.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu116 (from nvidia-cudnn-cu11->nvidia-tensorrt)\n  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-cudnn-cu116/nvidia_cudnn_cu116-8.4.0.27-py3-none-manylinux1_x86_64.whl (719.3 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m719.3/719.3 MB\u001b[0m \u001b[31m244.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu117->nvidia-cublas-cu11->nvidia-tensorrt) (68.1.2)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu117->nvidia-cublas-cu11->nvidia-tensorrt) (0.41.2)\nBuilding wheels for collected packages: nvidia-cublas-cu11, nvidia-cuda-runtime-cu11, nvidia-cudnn-cu11\n  Building wheel for nvidia-cublas-cu11 (setup.py): started\n  Building wheel for nvidia-cublas-cu11 (setup.py): finished with status 'done'\n  Created wheel for nvidia-cublas-cu11: filename=nvidia_cublas_cu11-2022.4.8-py3-none-any.whl size=15604 sha256=404cc0c0f301de66d72af43010540b05694d4d1dc0bc545eb364b97d0e2f1395\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3hzve997/wheels/8f/ed/66/aa1caefa04698673b59e1799fface640a8f6e840e59b9c27e3\n  Building wheel for nvidia-cuda-runtime-cu11 (setup.py): started\n  Building wheel for nvidia-cuda-runtime-cu11 (setup.py): finished with status 'done'\n  Created wheel for nvidia-cuda-runtime-cu11: filename=nvidia_cuda_runtime_cu11-2022.4.25-py3-none-any.whl size=15676 sha256=d53e11361dbff28d64e77e8359fcf0a57efbda9a2ffa5edbb2d518a1019e8824\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3hzve997/wheels/13/1a/0c/e13ce07df95cd19a0671df35ef74895be1f1bf2a62437aa1a9\n  Building wheel for nvidia-cudnn-cu11 (setup.py): started\n  Building wheel for nvidia-cudnn-cu11 (setup.py): finished with status 'done'\n  Created wheel for nvidia-cudnn-cu11: filename=nvidia_cudnn_cu11-2022.5.19-py3-none-any.whl size=15599 sha256=d1b997dab9282cda7c87abe6e8ee454925bce0933d0bd401be90adc87c57c13c\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3hzve997/wheels/dd/54/d7/1fe1c468474961cf9e43e85e89fa73b9d41f1608b70e753b03\nSuccessfully built nvidia-cublas-cu11 nvidia-cuda-runtime-cu11 nvidia-cudnn-cu11\nInstalling collected packages: nvidia-cudnn-cu116, nvidia-cuda-runtime-cu117, nvidia-cublas-cu117, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, nvidia-tensorrt\nSuccessfully installed nvidia-cublas-cu11-2022.4.8 nvidia-cublas-cu117-11.10.1.25 nvidia-cuda-runtime-cu11-2022.4.25 nvidia-cuda-runtime-cu117-11.7.60 nvidia-cudnn-cu11-2022.5.19 nvidia-cudnn-cu116-8.4.0.27 nvidia-tensorrt-8.4.3.1\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 52.4s, installed 1 package: ['nvidia-tensorrt']\n\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0...\n================ Diagnostic Run torch.onnx.export version 2.0.0 ================\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as /kaggle/working/yolov5/runs/train/exp5/weights/best.onnx (27.1 MB)\n\n\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 8.4.3.1...\n[01/27/2024-10:44:27] [TRT] [I] [MemUsageChange] Init CUDA: CPU +194, GPU +0, now: CPU 652, GPU 1012 (MiB)\n[01/27/2024-10:44:28] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +6, GPU +0, now: CPU 677, GPU 1012 (MiB)\n[01/27/2024-10:44:28] [TRT] [I] ----------------------------------------------------------------\n[01/27/2024-10:44:28] [TRT] [I] Input filename:   /kaggle/working/yolov5/runs/train/exp5/weights/best.onnx\n[01/27/2024-10:44:28] [TRT] [I] ONNX IR version:  0.0.7\n[01/27/2024-10:44:28] [TRT] [I] Opset version:    12\n[01/27/2024-10:44:28] [TRT] [I] Producer name:    pytorch\n[01/27/2024-10:44:28] [TRT] [I] Producer version: 2.0.0\n[01/27/2024-10:44:28] [TRT] [I] Domain:           \n[01/27/2024-10:44:28] [TRT] [I] Model version:    0\n[01/27/2024-10:44:28] [TRT] [I] Doc string:       \n[01/27/2024-10:44:28] [TRT] [I] ----------------------------------------------------------------\n[01/27/2024-10:44:28] [TRT] [W] onnx2trt_utils.cpp:369: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 512, 512) DataType.FLOAT\n\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 16128, 8) DataType.FLOAT\n\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as /kaggle/working/yolov5/runs/train/exp5/weights/best.engine\n[01/27/2024-10:44:28] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +32, now: CPU 710, GPU 1044 (MiB)\n[01/27/2024-10:44:28] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +36, now: CPU 710, GPU 1080 (MiB)\n[01/27/2024-10:44:28] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n[01/27/2024-10:45:24] [TRT] [I] Detected 1 inputs and 4 output network tensors.\n[01/27/2024-10:45:24] [TRT] [I] Total Host Persistent Memory: 128608\n[01/27/2024-10:45:24] [TRT] [I] Total Device Persistent Memory: 1051136\n[01/27/2024-10:45:24] [TRT] [I] Total Scratch Memory: 0\n[01/27/2024-10:45:24] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 0 MiB\n[01/27/2024-10:45:24] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 28.9548ms to assign 7 blocks to 139 nodes requiring 22806528 bytes.\n[01/27/2024-10:45:24] [TRT] [I] Total Activation Memory: 22806528\n[01/27/2024-10:45:24] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n[01/27/2024-10:45:24] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n[01/27/2024-10:45:24] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.\n\u001b[34m\u001b[1mTensorRT:\u001b[0m export success âœ… 111.3s, saved as /kaggle/working/yolov5/runs/train/exp5/weights/best.engine (34.4 MB)\n\nExport complete (111.6s)\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/train/exp5/weights\u001b[0m\nDetect:          python detect.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best.engine \nValidate:        python val.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best.engine \nPyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/kaggle/working/yolov5/runs/train/exp5/weights/best.engine')  \nVisualize:       https://netron.app\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nLoading /kaggle/working/yolov5/runs/train/exp5/weights/best.engine for TensorRT inference...\n[01/27/2024-10:45:24] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n\n[01/27/2024-10:45:24] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 709, GPU 1016 (MiB)\n[01/27/2024-10:45:24] [TRT] [I] Loaded engine size: 34 MiB\n[01/27/2024-10:45:24] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n[01/27/2024-10:45:24] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n/opt/conda/lib/python3.10/site-packages/tensorrt/__init__.py:166: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n  bool: np.bool,\nWARNING âš ï¸ Benchmark failure for TensorRT: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\nWARNING âš ï¸ Benchmark failure for CoreML: inference only supported on macOS>=10.13\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nFusing layers... \nModel summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /kaggle/working/yolov5/runs/train/exp5/weights/best.pt with output shape (1, 16128, 8) (13.7 MB)\n\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.0...\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [512, 512]]\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(1, 512, 512, 3)]           0         []                            \n                                                                                                  \n tf_conv (TFConv)            (1, 256, 256, 32)            3488      ['input_1[0][0]']             \n                                                                                                  \n tf_conv_1 (TFConv)          (1, 128, 128, 64)            18496     ['tf_conv[0][0]']             \n                                                                                                  \n tfc3 (TFC3)                 (1, 128, 128, 64)            18624     ['tf_conv_1[0][0]']           \n                                                                                                  \n tf_conv_7 (TFConv)          (1, 64, 64, 128)             73856     ['tfc3[0][0]']                \n                                                                                                  \n tfc3_1 (TFC3)               (1, 64, 64, 128)             115200    ['tf_conv_7[0][0]']           \n                                                                                                  \n tf_conv_15 (TFConv)         (1, 32, 32, 256)             295168    ['tfc3_1[0][0]']              \n                                                                                                  \n tfc3_2 (TFC3)               (1, 32, 32, 256)             623872    ['tf_conv_15[0][0]']          \n                                                                                                  \n tf_conv_25 (TFConv)         (1, 16, 16, 512)             1180160   ['tfc3_2[0][0]']              \n                                                                                                  \n tfc3_3 (TFC3)               (1, 16, 16, 512)             1181184   ['tf_conv_25[0][0]']          \n                                                                                                  \n tfsppf (TFSPPF)             (1, 16, 16, 512)             656128    ['tfc3_3[0][0]']              \n                                                                                                  \n tf_conv_33 (TFConv)         (1, 16, 16, 256)             131328    ['tfsppf[0][0]']              \n                                                                                                  \n tf_upsample (TFUpsample)    (1, 32, 32, 256)             0         ['tf_conv_33[0][0]']          \n                                                                                                  \n tf_concat (TFConcat)        (1, 32, 32, 512)             0         ['tf_upsample[0][0]',         \n                                                                     'tfc3_2[0][0]']              \n                                                                                                  \n tfc3_4 (TFC3)               (1, 32, 32, 256)             361216    ['tf_concat[0][0]']           \n                                                                                                  \n tf_conv_39 (TFConv)         (1, 32, 32, 128)             32896     ['tfc3_4[0][0]']              \n                                                                                                  \n tf_upsample_1 (TFUpsample)  (1, 64, 64, 128)             0         ['tf_conv_39[0][0]']          \n                                                                                                  \n tf_concat_1 (TFConcat)      (1, 64, 64, 256)             0         ['tf_upsample_1[0][0]',       \n                                                                     'tfc3_1[0][0]']              \n                                                                                                  \n tfc3_5 (TFC3)               (1, 64, 64, 128)             90496     ['tf_concat_1[0][0]']         \n                                                                                                  \n tf_conv_45 (TFConv)         (1, 32, 32, 128)             147584    ['tfc3_5[0][0]']              \n                                                                                                  \n tf_concat_2 (TFConcat)      (1, 32, 32, 256)             0         ['tf_conv_45[0][0]',          \n                                                                     'tf_conv_39[0][0]']          \n                                                                                                  \n tfc3_6 (TFC3)               (1, 32, 32, 256)             295680    ['tf_concat_2[0][0]']         \n                                                                                                  \n tf_conv_51 (TFConv)         (1, 16, 16, 256)             590080    ['tfc3_6[0][0]']              \n                                                                                                  \n tf_concat_3 (TFConcat)      (1, 16, 16, 512)             0         ['tf_conv_51[0][0]',          \n                                                                     'tf_conv_33[0][0]']          \n                                                                                                  \n tfc3_7 (TFC3)               (1, 16, 16, 512)             1181184   ['tf_concat_3[0][0]']         \n                                                                                                  \n tf_detect (TFDetect)        ((1, 16128, 8),              21576     ['tfc3_5[0][0]',              \n                             )                                       'tfc3_6[0][0]',              \n                                                                     'tfc3_7[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 7018216 (26.77 MB)\nTrainable params: 0 (0.00 Byte)\nNon-trainable params: 7018216 (26.77 MB)\n__________________________________________________________________________________________________\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 11.1s, saved as /kaggle/working/yolov5/runs/train/exp5/weights/best_saved_model (27.0 MB)\n\nExport complete (11.4s)\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/train/exp5/weights\u001b[0m\nDetect:          python detect.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best_saved_model \nValidate:        python val.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best_saved_model \nPyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/kaggle/working/yolov5/runs/train/exp5/weights/best_saved_model')  \nVisualize:       https://netron.app\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nLoading /kaggle/working/yolov5/runs/train/exp5/weights/best_saved_model for TensorFlow SavedModel inference...\nForcing --batch-size 1 square inference (1,3,512,512) for non-PyTorch models\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco128/labels/train2017.cache... 126 ima\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all        128        929   0.000589    0.00089   0.000205   7.56e-05\nSpeed: 0.2ms pre-process, 13.2ms inference, 1.3ms NMS per image at shape (1, 3, 512, 512)\nResults saved to \u001b[1mruns/val/exp5\u001b[0m\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nFusing layers... \nModel summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /kaggle/working/yolov5/runs/train/exp5/weights/best.pt with output shape (1, 16128, 8) (13.7 MB)\n\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.0...\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [512, 512]]\nModel: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_2 (InputLayer)        [(1, 512, 512, 3)]           0         []                            \n                                                                                                  \n tf_conv_57 (TFConv)         (1, 256, 256, 32)            3488      ['input_2[0][0]']             \n                                                                                                  \n tf_conv_58 (TFConv)         (1, 128, 128, 64)            18496     ['tf_conv_57[0][0]']          \n                                                                                                  \n tfc3_8 (TFC3)               (1, 128, 128, 64)            18624     ['tf_conv_58[0][0]']          \n                                                                                                  \n tf_conv_64 (TFConv)         (1, 64, 64, 128)             73856     ['tfc3_8[0][0]']              \n                                                                                                  \n tfc3_9 (TFC3)               (1, 64, 64, 128)             115200    ['tf_conv_64[0][0]']          \n                                                                                                  \n tf_conv_72 (TFConv)         (1, 32, 32, 256)             295168    ['tfc3_9[0][0]']              \n                                                                                                  \n tfc3_10 (TFC3)              (1, 32, 32, 256)             623872    ['tf_conv_72[0][0]']          \n                                                                                                  \n tf_conv_82 (TFConv)         (1, 16, 16, 512)             1180160   ['tfc3_10[0][0]']             \n                                                                                                  \n tfc3_11 (TFC3)              (1, 16, 16, 512)             1181184   ['tf_conv_82[0][0]']          \n                                                                                                  \n tfsppf_1 (TFSPPF)           (1, 16, 16, 512)             656128    ['tfc3_11[0][0]']             \n                                                                                                  \n tf_conv_90 (TFConv)         (1, 16, 16, 256)             131328    ['tfsppf_1[0][0]']            \n                                                                                                  \n tf_upsample_2 (TFUpsample)  (1, 32, 32, 256)             0         ['tf_conv_90[0][0]']          \n                                                                                                  \n tf_concat_4 (TFConcat)      (1, 32, 32, 512)             0         ['tf_upsample_2[0][0]',       \n                                                                     'tfc3_10[0][0]']             \n                                                                                                  \n tfc3_12 (TFC3)              (1, 32, 32, 256)             361216    ['tf_concat_4[0][0]']         \n                                                                                                  \n tf_conv_96 (TFConv)         (1, 32, 32, 128)             32896     ['tfc3_12[0][0]']             \n                                                                                                  \n tf_upsample_3 (TFUpsample)  (1, 64, 64, 128)             0         ['tf_conv_96[0][0]']          \n                                                                                                  \n tf_concat_5 (TFConcat)      (1, 64, 64, 256)             0         ['tf_upsample_3[0][0]',       \n                                                                     'tfc3_9[0][0]']              \n                                                                                                  \n tfc3_13 (TFC3)              (1, 64, 64, 128)             90496     ['tf_concat_5[0][0]']         \n                                                                                                  \n tf_conv_102 (TFConv)        (1, 32, 32, 128)             147584    ['tfc3_13[0][0]']             \n                                                                                                  \n tf_concat_6 (TFConcat)      (1, 32, 32, 256)             0         ['tf_conv_102[0][0]',         \n                                                                     'tf_conv_96[0][0]']          \n                                                                                                  \n tfc3_14 (TFC3)              (1, 32, 32, 256)             295680    ['tf_concat_6[0][0]']         \n                                                                                                  \n tf_conv_108 (TFConv)        (1, 16, 16, 256)             590080    ['tfc3_14[0][0]']             \n                                                                                                  \n tf_concat_7 (TFConcat)      (1, 16, 16, 512)             0         ['tf_conv_108[0][0]',         \n                                                                     'tf_conv_90[0][0]']          \n                                                                                                  \n tfc3_15 (TFC3)              (1, 16, 16, 512)             1181184   ['tf_concat_7[0][0]']         \n                                                                                                  \n tf_detect_1 (TFDetect)      ((1, 16128, 8),              21576     ['tfc3_13[0][0]',             \n                             )                                       'tfc3_14[0][0]',             \n                                                                     'tfc3_15[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 7018216 (26.77 MB)\nTrainable params: 0 (0.00 Byte)\nNon-trainable params: 7018216 (26.77 MB)\n__________________________________________________________________________________________________\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 5.3s, saved as /kaggle/working/yolov5/runs/train/exp5/weights/best_saved_model (27.0 MB)\n\n\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m starting export with tensorflow 2.13.0...\n\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m export success âœ… 2.0s, saved as /kaggle/working/yolov5/runs/train/exp5/weights/best.pb (27.0 MB)\n\nExport complete (7.5s)\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/train/exp5/weights\u001b[0m\nDetect:          python detect.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best.pb \nValidate:        python val.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best.pb \nPyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/kaggle/working/yolov5/runs/train/exp5/weights/best.pb')  \nVisualize:       https://netron.app\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nLoading /kaggle/working/yolov5/runs/train/exp5/weights/best.pb for TensorFlow GraphDef inference...\nForcing --batch-size 1 square inference (1,3,512,512) for non-PyTorch models\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco128/labels/train2017.cache... 126 ima\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all        128        929   0.000589    0.00089   0.000205   7.56e-05\nSpeed: 0.2ms pre-process, 12.1ms inference, 1.1ms NMS per image at shape (1, 3, 512, 512)\nResults saved to \u001b[1mruns/val/exp6\u001b[0m\nWARNING âš ï¸ Benchmark failure for TensorFlow Lite: inference not supported on GPU\nWARNING âš ï¸ Benchmark failure for TensorFlow Edge TPU: inference not supported\nWARNING âš ï¸ Benchmark failure for TensorFlow.js: inference not supported\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nFusing layers... \nModel summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /kaggle/working/yolov5/runs/train/exp5/weights/best.pt with output shape (1, 16128, 8) (13.7 MB)\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['paddlepaddle', 'x2paddle'] not found, attempting AutoUpdate...\nCollecting paddlepaddle\n  Obtaining dependency information for paddlepaddle from https://files.pythonhosted.org/packages/ea/16/c2fd65a994871bed5928a5997e3cd87169cceb12afe5aa26b5adb0467948/paddlepaddle-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata\n  Downloading paddlepaddle-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (8.6 kB)\nCollecting x2paddle\n  Downloading x2paddle-1.4.1-py3-none-any.whl (316 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m316.2/316.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting httpx (from paddlepaddle)\n  Obtaining dependency information for httpx from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.10/site-packages (from paddlepaddle) (1.24.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from paddlepaddle) (10.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from paddlepaddle) (5.1.1)\nCollecting astor (from paddlepaddle)\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: opt-einsum==3.3.0 in /opt/conda/lib/python3.10/site-packages (from paddlepaddle) (3.3.0)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from paddlepaddle) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from x2paddle) (1.12)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->paddlepaddle) (3.7.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->paddlepaddle) (2023.7.22)\nCollecting httpcore==1.* (from httpx->paddlepaddle)\n  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->paddlepaddle) (2.10)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->paddlepaddle) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->paddlepaddle) (0.14.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->x2paddle) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->paddlepaddle) (1.1.3)\nDownloading paddlepaddle-2.6.0-cp310-cp310-manylinux1_x86_64.whl (125.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m125.7/125.7 MB\u001b[0m \u001b[31m172.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m222.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m228.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: httpcore, astor, x2paddle, httpx, paddlepaddle\nSuccessfully installed astor-0.8.1 httpcore-1.0.2 httpx-0.26.0 paddlepaddle-2.6.0 x2paddle-1.4.1\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 18.9s, installed 2 packages: ['paddlepaddle', 'x2paddle']\n\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\nWARNING: OMP_NUM_THREADS set to 3, not 1. The computation speed will not be optimized if you use data parallel. It will fail if this PaddlePaddle binary is compiled with OpenBlas since OpenBlas does not support multi-threads.\nPLEASE USE OMP_NUM_THREADS WISELY.\n\n\u001b[34m\u001b[1mPaddlePaddle:\u001b[0m starting export with X2Paddle 1.4.1...\nExporting inference model from python code ('/kaggle/working/yolov5/runs/train/exp5/weights/best_paddle_model/x2paddle_code.py')... \n\nI0127 10:46:17.953661  1012 program_interpreter.cc:212] New Executor is Running.\n\u001b[34m\u001b[1mPaddlePaddle:\u001b[0m export success âœ… 24.0s, saved as /kaggle/working/yolov5/runs/train/exp5/weights/best_paddle_model/ (54.2 MB)\n\nExport complete (24.3s)\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/train/exp5/weights\u001b[0m\nDetect:          python detect.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best_paddle_model/ \nValidate:        python val.py --weights /kaggle/working/yolov5/runs/train/exp5/weights/best_paddle_model/ \nPyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/kaggle/working/yolov5/runs/train/exp5/weights/best_paddle_model/')  \nVisualize:       https://netron.app\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nLoading /kaggle/working/yolov5/runs/train/exp5/weights/best_paddle_model for PaddlePaddle inference...\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['paddlepaddle-gpu'] not found, attempting AutoUpdate...\nCollecting paddlepaddle-gpu\n  Obtaining dependency information for paddlepaddle-gpu from https://files.pythonhosted.org/packages/6b/9b/634ab295b004116c7717e226dbb1b52bd9c90b87b7acbf3470e8224c5815/paddlepaddle_gpu-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata\n  Downloading paddlepaddle_gpu-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (8.6 kB)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from paddlepaddle-gpu) (0.26.0)\nRequirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.10/site-packages (from paddlepaddle-gpu) (1.24.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from paddlepaddle-gpu) (10.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from paddlepaddle-gpu) (5.1.1)\nRequirement already satisfied: astor in /opt/conda/lib/python3.10/site-packages (from paddlepaddle-gpu) (0.8.1)\nRequirement already satisfied: opt-einsum==3.3.0 in /opt/conda/lib/python3.10/site-packages (from paddlepaddle-gpu) (3.3.0)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from paddlepaddle-gpu) (3.20.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu) (3.7.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu) (2023.7.22)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu) (1.0.2)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu) (2.10)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->paddlepaddle-gpu) (0.14.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->paddlepaddle-gpu) (1.1.3)\nDownloading paddlepaddle_gpu-2.6.0-cp310-cp310-manylinux1_x86_64.whl (749.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m749.8/749.8 MB\u001b[0m \u001b[31m237.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: paddlepaddle-gpu\nSuccessfully installed paddlepaddle-gpu-2.6.0\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 40.8s, installed 1 package: ['paddlepaddle-gpu']\n\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\nE0127 10:46:58.872861  1012 analysis_config.cc:125] Please use PaddlePaddle with GPU version.\nI0127 10:46:58.899968  1012 analysis_predictor.cc:1626] MKLDNN is enabled\n\u001b[1m\u001b[35m--- Running analysis [ir_graph_build_pass]\u001b[0m\nI0127 10:46:58.904291  1012 executor.cc:187] Old Executor is Running.\n\u001b[1m\u001b[35m--- Running analysis [ir_analysis_pass]\u001b[0m\n\u001b[32m--- Running IR pass [mkldnn_placement_pass]\u001b[0m\n\u001b[32m--- Running IR pass [simplify_with_basic_ops_pass]\u001b[0m\n\u001b[32m--- Running IR pass [layer_norm_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [attention_lstm_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [seqconv_eltadd_relu_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [seqpool_cvm_concat_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [mul_lstm_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [fc_gru_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [mul_gru_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [seq_concat_fc_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [gpu_cpu_squeeze2_matmul_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [gpu_cpu_reshape2_matmul_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [gpu_cpu_flatten2_matmul_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [matmul_v2_scale_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [gpu_cpu_map_matmul_v2_to_mul_pass]\u001b[0m\n\u001b[32m--- Running IR pass [gpu_cpu_map_matmul_v2_to_matmul_pass]\u001b[0m\n\u001b[32m--- Running IR pass [matmul_scale_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [gpu_cpu_map_matmul_to_mul_pass]\u001b[0m\n\u001b[32m--- Running IR pass [fc_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [repeated_fc_relu_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [squared_mat_sub_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_bn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_transpose_bn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_transpose_eltwiseadd_bn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [is_test_pass]\u001b[0m\n\u001b[32m--- Running IR pass [constant_folding_pass]\u001b[0m\nI0127 10:46:59.017107  1012 fuse_pass_base.cc:59] ---  detected 60 subgraphs\n\u001b[32m--- Running IR pass [squeeze2_transpose2_onednn_fuse_pass]\u001b[0m\n\u001b[37m--- fused 0 squeeze2 with transpose2\u001b[0m\n\u001b[32m--- Running IR pass [depthwise_conv_mkldnn_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_bn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_eltwiseadd_bn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_affine_channel_mkldnn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_transpose_bn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_transpose_eltwiseadd_bn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_bias_mkldnn_fuse_pass]\u001b[0m\nW0127 10:46:59.079885  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.080089  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.080231  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.080372  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.080531  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.080689  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.080839  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.080986  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.081132  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.081279  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.081461  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.081616  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.081764  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.081912  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.082057  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.082203  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.082350  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.082517  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.082667  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.082815  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.082962  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.083107  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.083256  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.083418  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.083564  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.083717  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.083865  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.084012  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.084161  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.084313  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.084511  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.084694  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.084879  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.085076  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.085260  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.085387  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.085520  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.085646  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.085767  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.085891  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.086011  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.086133  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.086256  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.086377  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.086508  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.086637  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.086759  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.086880  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.087002  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.087122  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.087244  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.087365  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.087493  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.087623  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.087744  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.087865  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.087987  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.088109  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.088236  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\nW0127 10:46:59.088382  1012 op_compat_sensible_pass.cc:232]  Check the Attr(axis) of Op(elementwise_add) in pass(conv_bias_mkldnn_fuse_pass) failed!\n\u001b[32m--- Running IR pass [conv_transpose_bias_mkldnn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_elementwise_add_mkldnn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [conv_activation_mkldnn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [scale_matmul_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [reshape_transpose_matmul_mkldnn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [matmul_transpose_reshape_mkldnn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [matmul_elementwise_add_mkldnn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [matmul_activation_mkldnn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [fc_mkldnn_pass]\u001b[0m\n\u001b[32m--- Running IR pass [fc_act_mkldnn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [self_attention_fuse_pass]\u001b[0m\n\u001b[37m---    fused 0 self attention (of scaled_dp_attention) with self_attention_fuse\u001b[0m\n\u001b[32m--- Running IR pass [batch_norm_act_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [softplus_activation_onednn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [shuffle_channel_mkldnn_detect_pass]\u001b[0m\n\u001b[32m--- Running IR pass [elementwise_act_onednn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [operator_scale_onednn_fuse_pass]\u001b[0m\nI0127 10:46:59.444046  1012 fuse_pass_base.cc:59] ---  detected 3 subgraphs\n\u001b[37m---    fused 3 elementwise_add with scale\u001b[0m\n\u001b[32m--- Running IR pass [operator_unsqueeze2_onednn_fuse_pass]\u001b[0m\n\u001b[32m--- Running IR pass [operator_reshape2_onednn_fuse_pass]\u001b[0m\n\u001b[1m\u001b[35m--- Running analysis [save_optimized_model_pass]\u001b[0m\n\u001b[1m\u001b[35m--- Running analysis [ir_params_sync_among_devices_pass]\u001b[0m\n\u001b[1m\u001b[35m--- Running analysis [adjust_cudnn_workspace_size_pass]\u001b[0m\n\u001b[1m\u001b[35m--- Running analysis [inference_op_replace_pass]\u001b[0m\n\u001b[1m\u001b[35m--- Running analysis [ir_graph_to_program_pass]\u001b[0m\nI0127 10:46:59.490165  1012 analysis_predictor.cc:1838] ======= optimize end =======\nI0127 10:46:59.492128  1012 naive_executor.cc:200] ---  skip [feed], feed -> x0\nI0127 10:46:59.494108  1012 naive_executor.cc:200] ---  skip [save_infer_model/scale_0.tmp_0], fetch -> fetch\nForcing --batch-size 1 square inference (1,3,512,512) for non-PyTorch models\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/coco128/labels/train2017.cache... 126 ima\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   I0127 10:46:59.546746  1012 onednn_context.cc:81] oneDNN v3.2.1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        128        929   0.000589    0.00089   0.000205   7.56e-05\nSpeed: 0.2ms pre-process, 155.8ms inference, 1.4ms NMS per image at shape (1, 3, 512, 512)\nResults saved to \u001b[1mruns/val/exp7\u001b[0m\n\n\n\u001b[34m\u001b[1mbenchmarks: \u001b[0mweights=/kaggle/working/yolov5/runs/train/exp5/weights/best.pt, imgsz=512, batch_size=1, data=/kaggle/working/yolov5/data/coco128.yaml, device=, half=False, test=False, pt_only=False, hard_fail=False\nChecking setup...\nFound existing installation: wandb 0.16.2\nUninstalling wandb-0.16.2:\n  Successfully uninstalled wandb-0.16.2\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nSetup complete âœ… (4 CPUs, 31.4 GB RAM, 5365.3/8062.4 GB disk)\n\nBenchmarks complete (261.66s)\n                   Format  Size (MB)  mAP50-95  Inference time (ms)\n0                 PyTorch        NaN       NaN                  NaN\n1             TorchScript       27.2    0.0001                 4.79\n2                    ONNX       27.1    0.0001                 8.14\n3                OpenVINO        NaN       NaN                  NaN\n4                TensorRT        NaN       NaN                  NaN\n5                  CoreML        NaN       NaN                  NaN\n6   TensorFlow SavedModel       27.0    0.0001                13.18\n7     TensorFlow GraphDef       27.0    0.0001                12.07\n8         TensorFlow Lite        NaN       NaN                  NaN\n9     TensorFlow Edge TPU        NaN       NaN                  NaN\n10          TensorFlow.js        NaN       NaN                  NaN\n11           PaddlePaddle       54.2    0.0001               155.80\n","output_type":"stream"}]},{"cell_type":"code","source":"!python detect.py --source /kaggle/input/ob-test/WIN_20240127_00_12_40_Pro.jpg --weights /kaggle/working/yolov5/runs/train/exp5/weights/best.pt","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:49:28.444753Z","iopub.execute_input":"2024-01-27T10:49:28.445233Z","iopub.status.idle":"2024-01-27T10:49:35.745643Z","shell.execute_reply.started":"2024-01-27T10:49:28.445196Z","shell.execute_reply":"2024-01-27T10:49:35.744388Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/kaggle/working/yolov5/runs/train/exp5/weights/best.pt'], source=/kaggle/input/ob-test/WIN_20240127_00_12_40_Pro.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\nYOLOv5 ðŸš€ v7.0-278-g050c72c Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\nFusing layers... \nModel summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\nimage 1/1 /kaggle/input/ob-test/WIN_20240127_00_12_40_Pro.jpg: 384x640 (no detections), 44.3ms\nSpeed: 0.6ms pre-process, 44.3ms inference, 5.1ms NMS per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/exp6\u001b[0m\n","output_type":"stream"}]}]}